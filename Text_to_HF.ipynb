{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Converts Text Files into HF Datasets"
      ],
      "metadata": {
        "id": "0CDYMJFD5HPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"text\", data_files={\"train\": \"./All_Books.txt\"})\n",
        "block_size=2032\n",
        "def group_texts(examples):\n",
        "    concatenated_examples = {k: ' '.join(examples[k]) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"text\"] = result[\"text\"].copy()\n",
        "    return result\n",
        "dataset=dataset.map(group_texts,batched=True)\n",
        "dataset.push_to_hub(\"eswardivi/books\")"
      ],
      "metadata": {
        "id": "qDEmabZPLpAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}